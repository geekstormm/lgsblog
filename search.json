[{"categories":["Linux"],"content":"系统物理内存初始化 ","date":"2024-12-30","objectID":"/posts/mmoverview/:1:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"1.0 关于内存的一些问题 内核通过什么手段来识别可用内存硬件范围的 内核管理物理内存用了哪些技术手段 为什么free -m显示的总内存总比dmicode输出的要少，少了的内存去哪里了 内核是如何知道某个内存地址范围属于那个NUMA的呢 NUMA (Non-Uniform Memory Access，非统一内存访问) 是一种内存设计架构，特点是： - 处理器可以访问自己的本地内存比访问非本地内存(远程内存)快 - 每个处理器都有自己的本地内存 - 处理器和内存被组织成\"节点\"(Node) ","date":"2024-12-30","objectID":"/posts/mmoverview/:2:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"1.1 从固件开始 将内存放到硬件层面，本质上就是带有一根根触角的硬件。操作系统需要识别到这些内存才能进行使用。那么操作系统如何知道内存等硬件信息的呢？答案是固件，也就是我们常说的UEFI/BIOS，固件是操作系统和硬件的中间层，在硬件上电后，在操作系统启动之前，实际上最先启动的是固件程序，固件会进行硬件自检，初始化硬件程序，电源功能管理等功能，同时操作系统需要用到的内存信息也是通过固件来获取的。 在固件启动前，硬件会做上电，处理器复位，内存控制器初始化，芯片组初始化等操作。 UEFI（Unified Extensible Firmware Interface）: BIOS的继任者，更现代化 BIOS（Basic Input/Output System） 固件的职责从上电到启动依次包括： POST（Power-on Self-test），上电，自检，如CPU，内存，外设等。 硬件初始化 设备枚举以及初始化 ACPI表（Advanced Configuration and Power Interface，高级配置与电源接口）创建（根据设备资源生成ACPI表） 引导设备准备（通常是硬盘、固态硬盘或网络启动设备），UEFI架构中包括找到Bootloader（比如GRUB） 向Bootloader转交控制权 ","date":"2024-12-30","objectID":"/posts/mmoverview/:3:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"1.2 物理内存安装检测 在操作系统启动后，会去探测可用的内存范围，具体操作是，前面固件的ACPI表提供了内存探测的物理分布规范，内核设置中断号为15H，并设置操作码为E820 H。然后就会执行detect_memory操作。 detect_memory会将可用内存信息保存到boot_params.e820_table 对象中，内核后续会将boot_params.e820_table 中的信息存到全局变量e820_table中（通过e820_memory_setup函数）。 内核启动过程中的输出信息可以通过dmesg命令来查看。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:4:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"1.3 memblock内存分配器 内存分配器分为两种，一种是刚启动时的初期分配器，这个内存管理粒度大，只是为了满足系统启动时对内存页的简单管理。另一种是系统启动后的伙伴系统（Buddy System）。 上面说到调用完e820_memory_setup函数，可用的内存信息就已经存到了全局对象e820_table中。随后调用e820_memblock_setup创建memblock内存分配器。 memblock的逻辑很简单，就是按照检测到的地址范围是usable还是reserved，然后分别用一个memblock_region数组存起来。具体的过程就是遍历e820_table ，然后类型存储到对应的数组中。 memblock创建完成后会有一个memblock_dump_all的函数来一次打印所有信息，前提是打开了debug参数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void __init_memblock memblock_dump_all(void) { if (memblock_debug) __memblock_dump_all(); } static void __init_memblock __memblock_dump_all(void) { pr_info(\"MEMBLOCK configuration:\\n\"); pr_info(\" memory size = %pa reserved size = %pa\\n\", \u0026memblock.memory.total_size, \u0026memblock.reserved.total_size); memblock_dump(\u0026memblock.memory); memblock_dump(\u0026memblock.reserved); #ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP memblock_dump(\u0026physmem); #endif } ","date":"2024-12-30","objectID":"/posts/mmoverview/:5:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"1.4 向memblock申请内存 在伙伴系统创建之前，所有的内存都是通过memblock来分配的，这里面有两个重要的场景，一个是crash kernel内存申请，一个是页管理初始化。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:6:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"Crash Kernel 内存申请 首先要清楚，crash kernel不是program kernel。crash kernel的设计是为了kernel在崩溃时可以记录崩溃现场，方便后续排查分析。crash kernel基于kdump机制，在内核崩溃时，kdump会使用kexec来启动第二个内核，这样就可以保留第一个内核内存以及其运行状态。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:6:1","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"页管理初始化 Linux的伙伴系统是按页来管理内存的，页的大小是4kb，前面我们知道memblock管理的内存粒度很大，那么内核是如何将memblock的内存转化成页来管理的呢。 在kernel中有一个页管理模型，具体初始化函数是paging_init，在这个函数中为所有的page都申请了一个struct page对象，通过这个对象对页进行管理。 现代页管理模型都是SPARSEMEM模型，也就是通过二维数据对页进行管理，SPARESEMEM模型大致组成如下： 1 2 3 4 5 6 7 8 // 第一维数组 struct mem_section *mem_section[NR_SECTION_ROOTS]; // 第二维数组 struct mem_section { unsigned long section_mem_map; unsigned long *pageblock_flags; }; 具体来说，mem_section数组用于索引内存根目录，大小为NR_SECTION_ROOTS，每个元素指向一组section。实际的section数组每个section管理一段连续的物理内存，通常每个section大小为128MB，使用section_mem_map指向实际的页面。 而每一个struct page的大小一般为64字节，而每一个页是4KB，64/4096大致为1.6%，那么16GB的内存就会有大约256M的内存需要用来管理页。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:6:2","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"1.5 NUMA 在继续内存管理之前，需要先了解一下NUMA。（Non-Uniform Memory Access，非统一内存访问）是一种内存设计架构，将处理器和内存组织成多个节点（Node）。每个Node包含CPU，本地内存，I/O设备。在内核的实现中，每一个Node用pglist_data结构体表示。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 //Linux6.8.8 mmzone.h typedef struct pglist_data { // 该节点包含的所有zone struct zone node_zones[MAX_NR_ZONES]; // 节点的zonelist，用于内存分配失败时的备用列表 struct zonelist node_zonelists[MAX_ZONELISTS]; // 节点ID int node_id; // 节点中zone的数量 int nr_zones; // 节点的页面映射 struct page *node_mem_map; // 节点的起始页帧号 unsigned long node_start_pfn; // 实际存在的页面数 unsigned long node_present_pages; // 节点跨越的总页面数（包括空洞） unsigned long node_spanned_pages; // 节点状态标志 unsigned long node_flags; } pg_data_t; 这样做的原因是，随着计算机的发展，单个机器的CPU和内存越来越多，而CPU是有缓存一致性（Cache Coherency）的限制。在传统的SMP（对称多处理器）架构中，所有CPU共享同一个内存总线，当CPU数量增加时会导致总线竞争，缓存一致性开销和CPU扩展性限制。NUMA的出现使得这三个问题都得以解决。 这种架构的好处是CPU访问同一个Node的时候延迟低，带宽高，也就是说本地内存访问快，远程内存访问慢，一般而言，本地内存访问在100ns左右，跨Node访问则在300ns左右。 那么内核在启动的时候如何知道NUMA信息呢，答案是ACPI表，ACPI表中存在两个表，分别是SRAT（System Resource Affinity Table）和SLIT（System Locality Information Table），这两个表描述了NUMA拓扑。在操作系统启动的时候会去读这两个表，然后把NUMA信息存到numa_meminfo这个全局的结构体中。 1 2 3 4 5 // Linux6.8.8 numa.h struct numa_meminfo { int nr_blks; struct numa_memblk blk[NR_NODE_MEMBLKS]; }; 到这里为止内核创建好了memblock分配器，也通过ACPI表知道了NUMA信息。接下来就是把NUMA信息和memblock关联起来。简单来说就是为每一个Node申请一个前面说明的pglist_data内核对象，并将memblock region与Node关联起来。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:7:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"伙伴系统 前面说过内核启动后会通过ACPI表中的NUMA信息为每个Node创建一个内核对象。但是内核不可能这么简单的来管理每个Node，毕竟每个Node的内存是相当大的。因此内核为了更好的管理Node，会在每个Node下创建Zone，Zone的类型分为三种： ZONE_DMA：支持ISA设备DMA访问 ZONE_DMA32：在64位系统中支持32位设备DMA访问 ZONE_NORMAL：其余的全部都是NORMAL 在每个zone下都有很多个page，也就是页，Linux下page大小一般是4KB。 可以通过cat /proc/zoneinfo 来查看机器具体的zone划分。 那么zone那么多的page是如何进行管理的呢，就是本节的标题，伙伴系统（Buddy System）。首先来看zone中内核的实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Linux 6.8.8 include/linux/mmzone.h struct zone { /* Read-mostly fields */ char *name; unsigned long zone_start_pfn; atomic_long_t managed_pages; unsigned long spanned_pages; unsigned long present_pages; /* free areas of different sizes */ struct free_area free_area[MAX_ORDER]; /* zone flags, see below */ unsigned long flags; /* Write-intensive fields used from the page allocator */ spinlock_t lock; // ... 更多字段 ... }; 注意到zone中有一个结构体数据free_area，这个就是伙伴系统的核心数据结构。到这里我们就可以大致知道内核的内存架构层次了： 1 2 3 4 5 6 7 Node (NUMA节点) ｜ struct pglist_data ↓ ｜ Zone (内存区域：DMA、NORMAL等) ｜ struct zone ↓ ｜ Buddy System (伙伴系统，包含free_area等) ｜ struct free_area ↓ ｜ Page (物理页面) ｜ Node是NUMA中的概念，每个Node都有多个zone，伙伴系统在zone的层面工作，每个zone都有自己的伙伴系统，也就是free_area数组。Node是NUMA下最大的内存单元，伙伴系统是每个zone中实现的内存管理机制，Node主要用于NUMA系统中的内存单元管理，具体的页面管理由伙伴系统负责。 free_area实际是一个数组，这个数组有MAX_PAGE_ORDER + 1个元素，也就是11个元素，元素依次管理是4KB、8KB、16KB的连续内存块。 实际分配页面时的工作流： 1 2 3 4 // 分配内存时的层次调用 alloc_pages() → get_page_from_freelist() // 在zonelist中查找合适的zone → __rmqueue() // 在zone的伙伴系统中分配页面 实际alloc_pages 执行的操作是就是上学时操作系统教材上说的那一套策略了，比如相邻的合并，没有会向上级申请并裂变。现在的Linux Kernel在细节上做了很多优化，比如延迟合并，保持热页面，迁移类型隔离等等。 最后memblock会将内存完全交接给伙伴系统。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:8:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"进程如何使用内存 ","date":"2024-12-30","objectID":"/posts/mmoverview/:9:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"3.0 虚拟内存背景 虚拟内存这个概念最早出现于论文One-Level Storage System，是上世纪70年代的论文，比Linux早很多。当时的背景下内存容量十分有限并且非常昂贵。程序稍微一大就会受到内存限制，以至于不能一次性在内存中完整运行。当时对于内存的需求远超硬件能提供的容量。传统的做法是程序员手动实现overlay（覆页），或者操作系统粗糙的进行内存与磁盘的调度，这种方式工作量大并且效率低下。在这样的背景下如何在有限的内存下运行大程序成为了热门话题。 虚拟内存的出现让机器可以运行远远大于内存的程序，因为程序通过虚拟内存会认为自己拥有从0开始的一大片地址，其实背后都是虚拟内存在调度，一般来说程序只会在物理内存中保留一些常用的页。 正是这种设计不仅使得程序设计变得简单（程序员不再需要具体为内存不足或者地址冲突等问题费神），对于系统的吞吐量以及后面的内存保护以及进程隔离等机制奠定了基础。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:10:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"3.1 虚拟内存与物理页 在Linux Kernel中，虚拟内存的管理是以进程为单位的，每个进程都有一个虚拟地址空间。具体到实现上，每个进程的task_struct都有一个mm_struct类型的核心对象mm，它表示的就是进程的虚拟地址空间。 1 2 3 4 5 6 7 // Linux6.8.8 include/linux/sched.h struct task_struct { // ... struct mm_struct *mm; struct mm_struct *active_mm; // ... }; 在Linux6.1的版本之前，mm_struct用vm_area_struct（核心是红黑树）来管理VMA（Virtual Memory Area）。 vm_start 和 vm_end表示虚拟地址范围的开始和结束。进程中会有很多个vm_area_struct对象，每个vm_area_struct对象都会有自己的vm_start和vm_end，加起来就是对整个虚拟地址空间的占用情况。而因为进程中的vm_area_struct太多，在内存访问的时候进程需要查vm_area_struct和虚拟地址的对应关系，就需要一种高效的数据架构来进行管理以便进行遍历和查询，这就引入了红黑树+双链表。红黑树可以快速查找特定地址的VMA，引入双链表的目的是加速遍历以及找到相邻的VMA（合并时很重要）。 1 2 3 4 5 6 7 8 9 10 11 12 struct mm_struct{ // Linux 6.1以前 struct rb_root mm_rb; // 红黑树根 struct vm_area_struct *mmap; // 按地址排序的双向链表头 } struct vm_area_struct { struct mm_struct *vm_mm; // 指向所属mm_struct struct rb_node vm_rb; // 红黑树节点 struct list_head vm_next; // 链表节点 // ... }; 在现在的版本中，使用了maple_tree来管理VMA（核心是线段树）。主要的原因是服务器上的核现在越来越多，线程页越来越多，多线程之间的锁竞争越来越严重，而红黑树的每次操作都需要加锁，因为涉及到树的平衡，并且还需要同步双向链表，基于这两个原因，就必须加锁。而maple_tree基于RCU（read-copy-update）实现了线程安全的无锁数据结构，大大降低了锁的开销。 并且maple_tree因为基于线段树，因此能提供范围查询，高效的相邻节点访问以及双向遍历。等于用一个数据结构完成了两个组合数据结构的功能。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct mm_struct { struct maple_tree mm_mt; // 使用maple tree存储VMA // ... }; // ma_root指针存储和管理vma struct maple_tree { union { spinlock_t ma_lock; lockdep_map_p ma_external_lock; }; unsigned int ma_flags; void __rcu *ma_root; }; ","date":"2024-12-30","objectID":"/posts/mmoverview/:11:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"3.1.1 缺页中断 用户进程申请内存的时候，申请的只是一个vm_area_struct，也就是说只是一段地址范围。不是实际分配物理内存，具体的分配发生在实际访问的时候。进程运行时，需要访问变量，如果物理页还未分配就会触发缺页中断。 在 x86_64 Linux 内核中，触发缺页异常 (#PF) 后，最终会调用到 do_page_fault()，而 do_page_fault() 里又会根据具体情况（如发生在用户态还是内核态，是否合法地址等）调用到 do_user_addr_fault() 来进一步处理用户态的缺页异常。在Linux6.8.8中的具体处理如下，不同于6.1以前的红黑树，在这里查找也是用的线段树。 1 2 3 4 5 6 7 8 // Linux 6.8.8 arch/x86/mm/fault.c static inline void do_user_addr_fault(struct pt_regs *regs,unsigned long error_code, unsigned long address) { // ... vma = lock_vma_under_rcu(mm, address); fault = handle_mm_fault(vma, address, flags | FAULT_FLAG_VMA_LOCK, regs); // ... } 在找到vma后，内核会调用handle_mm_fault，随后通过__handle_mm_fault来完成真正的物理内存申请。 1 2 3 4 vm_fault_t handle_mm_fault(struct vm_area_struct *vma, unsigned long address, unsigned int flags, struct pt_regs *regs) { ret = __handle_mm_fault(vma, address, flags); } 在__handle_mm_fault中会先去检测四级页表，如果不存在就申请创建，页表完整后再去调用 1 2 -\u003ehandle_pte_fault -\u003e do_pte_missing(vmf); -\u003edo_anonymous_page(vmf); do_anonymous_page(vmf)的内存实际来源于伙伴系统，到此为止完成真正的内存分配。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:11:1","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"虚拟内存使用方式 到这里可以从可执行文件开始到进程运行时捋一下：在进程加载的过程中，解析完ELF文件后（加载完成后实际上就已经初始化了），将为进程创建一个新的地址空间，以及一个4KB大小的栈；随后将可执行文件以及所依赖的库通过elf_map映射到虚拟内存中；最后还会进行堆区的初始化。 展开来说，所有的行为都集中在load_elf_binary()中，load_elf_binary() 读取 ELF 头及 Program Header Table (PHT)，针对每个 PT_LOAD 段，调用内核的 mmap()（底层是 do_mmap()) 来映射到指定虚拟地址： 创建 VMA：do_mmap() 会分配一个新的 vm_area_struct，设置 vm_start, vm_end, vm_page_prot（读、写、执行权限），以及对应的 vm_file 等信息； 将这个 VMA 挂到当前进程的 mm-\u003emmap 链表或红黑树里，并更新 mm-\u003emap_count, total_vm 等统计； 目的：将 ELF 中的 .text 段（代码，只读可执行），.rodata 段（只读数据），.data 段（可写数据），.bss（零初始化段）等都按需映射到相应的虚拟地址。 如果是动态链接的 ELF，则还会额外处理 PT_INTERP 段，去加载动态链接器本身（它也是一个 ELF），然后再为它映射对应的区域。 当各段加载好以后，内核还要为进程分配并设置用户态栈：调用 setup_arg_pages() 等函数，为 argv[], envp[] 以及 auxv[] 分配空间，写入到用户态栈中； 同时记录下新进程栈的顶部地址，比如 mm-\u003estart_stack； ","date":"2024-12-30","objectID":"/posts/mmoverview/:12:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"execve的行为 execve的原型为： 1 int execve(const char *filename, char *const argv[], char *const envp[]); 在用户执行execve的时候，会触发如下的路径： 用户态 通过软中断（或 syscall 指令等）进入内核态，调用内核提供的 __do_sys_execve()。 内核态 __do_sys_execve() 这是 syscall handler，读取用户传入的参数（文件名、argv、envp），然后调用： do_execve() 进行一些初步检查后，最终调用： do_execveat_common() 这里是更通用的实现，处理路径解析、flags 等，最终打开要执行的文件，形成一个 file * 结构，再调用： do_execve_file() 给“待执行文件”创建并初始化 linux_binprm 结构（简称 bprm，存放将要被加载执行的程序相关的信息，如命令行参数、环境变量、打开的文件指针等），随后调用： exec_binprm() 这是加载用户程序的核心入口函数，内部会调用注册在系统中的各类二进制格式处理器（例如 ELF, script, a.out 等）。在 Linux 中最常见的就是 ELF 格式处理器，也就是 load_elf_binary()。 其调用逻辑类似： 1 2 3 int exec_binprm(struct linux_binprm *bprm) { return search_binary_handler(bprm); } load_elf_binary() 检查 ELF Header 初始化新进程的内存描述，ELF 解析通过后，会先对原有进程进行“替换式”加载，也就是说，需要废弃旧内存布局，准备建立新内存布局。 解析 Program Header Table，ELF 文件中的 Program Header Table 指示可执行文件中各段（Segment）的加载方式（可执行、可写、可读等），其结构为 struct elf_phdr。load_elf_binary() 会逐个解析 p_type == PT_LOAD 的段，然后进行相应的 mmap() 操作，将这些段映射到目标进程的虚拟地址空间中。 设置进程入口点 处理解释器段（动态链接器） 建立用户栈 设置进程各项元数据 完成加载 \u0026 返回 可以简化为： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 用户态调用 execve(filename, argv, envp); // 进入内核态（SYSCALL） __do_sys_execve() -\u003e do_execve(filename, argv, envp) -\u003e do_execveat_common() -\u003e do_execve_file(file, argv, envp, flags) -\u003e exec_binprm(bprm) -\u003e search_binary_handler(bprm) -\u003e load_elf_binary(bprm) // 如果文件是 ELF [解析 ELF Header] [解析 Program Header Table] [mmap(PT_LOAD) 段] （创建VMA并挂到mm-\u003emmap上） [如果有 PT_INTERP =\u003e load_elf_interp()] [setup_arg_pages() 构建用户栈，一般初始是4KB] [start_thread() 设置入口点] -\u003e ... //准备用户态寄存器并返回 // 设置 RIP/EIP = e_entry // 栈指针 = 新的用户栈地址 // 返回到用户态开始执行 ","date":"2024-12-30","objectID":"/posts/mmoverview/:12:1","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"进程栈内存的使用 我们这里聊到的栈实际都是用户栈，与之对应的概念的是内核栈，后面有空再补。上面已经说了进程在创建完成后，虚拟内存大致的布局。就是初始的4KB，并且在最后执行start_thread(regs, e_entry, stack_ptr)的时候会把并把 栈指针（RSP/ESP）设置到我们刚刚分配好的用户栈顶。 内核栈（kernel stack）： 每个进程/线程在内核态都有一块固定大小的栈（如 x86_64 典型 16KB，两页）。 分配时机：在 fork() / clone() 的 copy_process() 中由 alloc_thread_info_node() 等完成。 用途：当进程陷入内核态（系统调用、中断、异常）时使用，用于保存内核态的函数调用帧、局部变量等。 大小固定，不会像用户态栈那样自动扩张。 用户态栈（user stack）： 是我们上文描述的那块由进程自己使用的栈，从高地址向低地址增长，默认可扩展至一定限制（由内核 VMA + ulimit -s 控制）。 分配时机：在 execve() 的 setup_arg_pages() 时初始建立；运行时通过 expand_stack() 等逻辑动态增大。 大小可变，受进程的内存限制和操作系统策略管控。 在 x86/x86_64 等多数架构上，用户态栈地址从高地址往低地址方向增长。也就是说，在 C 语言里调用函数、压入局部变量时，栈指针会不断减小。当栈帧变大或深度增加时，就需要更多的内存空间。 内核里有一个约定：用户栈对应的虚拟内存区域具有 VM_GROWSDOWN 标志。这意味着如果进程访问了比当前栈底（vma-\u003evm_start）更低的地址，而且仍在“可增长区间”内，内核会尝试“向下扩展”这块栈 VMA，从而容纳新的栈数据。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:13:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"动态扩展 当用户态执行某些操作，导致栈指针（RSP/ESP）越过了当前 VMA 的边界，就会触发一个 缺页异常（page fault）。内核的缺页异常处理大致会经过以下函数（以 x86_64 为例，路径和名称在不同内核版本里略有差异）： do_page_fault() (位于 arch/x86/mm/fault.c 等) 入口点，处理所有用户/内核缺页异常； 自用户态还是内核态？）； handle_mm_fault() (位于 mm/memory.c 等) 件映射？匿名映射？栈？）去做相应的处理； _GROWSDOWN 标志的栈 VMA 之下，内核会调用 expand_stack(vma, address) 或类似流程。 xpand_downwards() (位于 mm/mmap.c) 这是栈自动扩展的核心函数之一； 检查要扩展的地址 address 是否“合理”，比如不能无限制扩到进程地址空间之外、或者超出 ulimit -s 等限制； vma-\u003evm_start 到更低的地址，腾出更多虚拟地址空间供栈使用； 随后故障页就可以通过正常的缺页处理分配物理页，完成映射。 这样一来，进程的栈空间就会 “无缝” 地向下扩展——对用户程序来说，这一切自动发生，只要没超限，就可以继续使用。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:13:1","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"线程栈内存的使用 首先要明确一个事情，在 Linux 内核中，“线程”与“进程”本质上都是 task_struct，只是在一些资源是否共享（如 mm_struct）方面有不同的 clone 标志位。二者在内核视角下非常相似，但在用户空间（尤其是 C/POSIX 线程库）会有额外的栈管理逻辑。 创建线程一般都是通过调用pthread_create()，这个函数底层是clone() 系统调用（或更底层的 clone3()）来创建一个新任务（新“线程”）。它与“普通进程”最大的区别是：新线程与父线程共享 mm_struct（地址空间、代码段、数据段等），而不是像新进程那样复制/独立地址空间。 sys_clone() / sys_clone3()是 syscall 的入口点；负责解析用户传入的寄存器地址、栈地址、标志位（如 CLONE_VM, CLONE_FS, CLONE_FILES, CLONE_SIGHAND）等。 随后调用copy_process()分配新的 task_struct 和内核栈（通过 alloc_thread_info()），判断 clone_flags 里有没有 CLONE_VM： 如果 有 CLONE_VM，则新任务与父任务共享地址空间（mm_struct），这就变成了线程； 如果 没有 CLONE_VM，会 copy 一份 mm_struct，就像传统的进程 fork()； 对于线程，只保留一个 mm_struct 引用计数 +1（即不创建新的 mm）。设置好寄存器上下文，包括指令指针、栈指针（从用户态传来的那个“thread stack top”）。 但是，一个新的线程也需要自己的 “用户态栈”。这块栈往往是由用户层的线程库（例如 glibc 的 pthread 实现）使用 mmap() 或者从进程堆里分配一段内存来当作线程栈。 pthread 库的做法（简要） 当你调用 pthread_create(\u0026tid, \u0026attr, start_routine, arg) 时，pthread 库内部会： 如果用户没有自行指定 pthread_attr_setstack()，则库会用 mmap() 分配一块内存作为“新线程栈”； 设置好这块内存区域的保护属性（PROT_READ|PROT_WRITE），并在用户层记录其起始地址、大小； 调用 clone() 系统调用时，将“新线程入口函数（start_routine）”以及“用户态栈顶地址”一起传给内核，让内核知道“进入用户态后，该线程从哪块栈开始执行”。 内核对用户栈并不“主动分配” 与进程的“主线程栈”在 execve() 里通过 setup_arg_pages() 分配不同，新线程的用户栈是由用户层自己准备的（pthread 库做的那一堆 mmap() 或内存管理），再把栈顶指针告诉内核。 在内核看来，这些线程共用同一个 mm_struct，即同一个虚拟地址空间，只是每个线程有不同的寄存器上下文（包括不同的用户态栈指针）、以及不同的内核栈。 是否支持 VM_GROWSDOWN 对于“主线程”的栈，Linux 常常把它标记为带 VM_GROWSDOWN，以支持自动扩展； 对于“额外创建的线程栈”，取决于 pthread 库是否设置了相应的标志：通常 pthread 是固定大小的栈，不一定使用 VM_GROWSDOWN（或者只在一定范围内可扩展），因为该栈往往由库分配的一片匿名映射区域（mmap），不一定也不总是带自动扩展标志。 如果库或用户手动使用 MAP_GROWSDOWN 标志，也能生成类似“向下扩展”的 VMA，但这是实现细节，大多数常见的 pthread 实现里都是定长栈。 对比： 线程栈内存的使用：主要由用户空间的线程库来负责分配(固定大小或自定义)；内核在 clone() → copy_process() 时只需要记住“返回用户态时要用哪块栈”。 对比进程：进程在 execve() 时，由内核 setup_arg_pages() 创造“主线程栈”并可自动扩展；线程则没有单独 execve() 的过程，只是共享地址空间、共享可执行文件映射，各自使用用户层分配好的栈。 ","date":"2024-12-30","objectID":"/posts/mmoverview/:14:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["Linux"],"content":"进程堆的内存管理 待补充 ","date":"2024-12-30","objectID":"/posts/mmoverview/:15:0","tags":["Linux","Memory"],"title":"Linux内存子系统","uri":"/posts/mmoverview/"},{"categories":["C++"],"content":"引言 ","date":"2024-12-17","objectID":"/posts/funtional/:1:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function是什么 std::function 是 C++11 引入的通用可调用对象包装器，用于封装函数、函数对象、Lambda 表达式以及 std::bind 返回的对象等各种可调用类型。它提供了统一的接口，能够在运行时存储和调用这些对象。 本质上就是一个模板类，它主要用来存储和调用可调用对象（通函数，lambda，重载了operator()的类，类的成员函数指针，std::bind的结果）。 ","date":"2024-12-17","objectID":"/posts/funtional/:1:1","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"为什么需要 std::function？ 传统函数指针的局限性：只能指向函数，无法直接适配仿函数或 Lambda 表达式。 多态性的需求：不同类型的可调用对象可以被统一存储和调用。 代码灵活性：可以作为参数传递、存储回调函数、实现事件驱动等机制。 典型的适用场景有： 回调函数机制（如事件触发、异步任务） 函数作为参数传递 组合不同可调用对象的接口（如策略模式） ","date":"2024-12-17","objectID":"/posts/funtional/:1:2","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function基本用法 包装普通函数 1 2 3 4 5 6 7 8 9 10 11 12 #include \u003cfunctional\u003e #include \u003ciostream\u003e void greet(int age) { std::cout \u003c\u003c \"Hello, your age is \" \u003c\u003c age \u003c\u003c std::endl; } int main() { std::function\u003cvoid(int)\u003e func = greet; // 包装普通函数 func(25); // 调用函数 return 0; } 包装 Lambda 表达式 std::function 支持 Lambda 表达式，非常适合简洁的逻辑封装。 1 2 3 4 5 6 7 8 9 10 #include \u003cfunctional\u003e #include \u003ciostream\u003e int main() { auto lambda = [](int x) { std::cout \u003c\u003c \"Lambda says: \" \u003c\u003c x \u003c\u003c std::endl; }; std::function\u003cvoid(int)\u003e func = lambda; // 包装 Lambda func(42); // 调用 return 0; } 包装仿函数（函数对象） 函数对象是通过重载 operator() 的类或结构体，可以像函数一样被调用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u003cfunctional\u003e #include \u003ciostream\u003e struct Functor { void operator()(int x) const { std::cout \u003c\u003c \"Functor called with x = \" \u003c\u003c x \u003c\u003c std::endl; } }; int main() { Functor functor; std::function\u003cvoid(int)\u003e func = functor; // 包装仿函数 func(100); return 0; } 包装成员函数与 std::bind 成员函数不能直接通过 std::function 绑定，需要借助 std::bind。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u003cfunctional\u003e #include \u003ciostream\u003e class MyClass { public: void show(int x) { std::cout \u003c\u003c \"MyClass::show called with x = \" \u003c\u003c x \u003c\u003c std::endl; } }; int main() { MyClass obj; auto bound_func = std::bind(\u0026MyClass::show, obj, std::placeholders::_1); std::function\u003cvoid(int)\u003e func = bound_func; // 包装成员函数 func(200); // 调用 MyClass::show(200) return 0; } ","date":"2024-12-17","objectID":"/posts/funtional/:2:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function与std::bind std::bind返回的结果是一个可调用对象，并可以将参数进行绑定 语法： 1 std::bind(function, arg1, arg2, ..., std::placeholders::_1); std::placeholders::_1 表示占位符，调用时由实际参数替代。 适合部分参数固定的场景。 ","date":"2024-12-17","objectID":"/posts/funtional/:3:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function的性能与开销 ","date":"2024-12-17","objectID":"/posts/funtional/:4:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function 的内部实现 std::function 使用了一种叫 类型擦除（Type Erasure） 的技术来适配不同的可调用对象类型。 类型擦除的原理： std::function 内部会存储一个指向基类的指针，并通过多态实现对可调用对象的统一管理。 它会将不同类型的可调用对象（普通函数、Lambda、仿函数等）转换为一个内部通用接口。 虽然这种机制提供了高度灵活性，但会带来一定的 运行时开销。 ","date":"2024-12-17","objectID":"/posts/funtional/:4:1","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function 的开销与代价 动态内存分配：对于较大的可调用对象（如捕获很多变量的 Lambda），std::function 可能会动态分配内存。 额外间接调用：由于多态和类型擦除机制，调用封装的函数时会增加一次间接调用的开销。 ","date":"2024-12-17","objectID":"/posts/funtional/:4:2","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"避免开销的方法 在性能敏感的场景中，可以考虑以下替代方案： 直接使用模板函数：模板参数在编译时确定类型，零开销。 使用 auto：C++14 及以上版本中，auto 类型推导能直接保存可调用对象。 使用 std::invoke：C++17 引入的 std::invoke 是一种轻量级的可调用对象调用器。 ","date":"2024-12-17","objectID":"/posts/funtional/:4:3","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"常见应用场景 这里只说我在工作中常实践的几个场景 ","date":"2024-12-17","objectID":"/posts/funtional/:5:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"回调函数 实际中一般是通过 \u003cstring, callback\u003e 的方式进行注册，在此处为简单起见并没有使用。 1 2 3 4 5 6 7 8 9 10 11 12 #include \u003cfunctional\u003e #include \u003ciostream\u003e void registerCallback(std::function\u003cvoid()\u003e callback) { std::cout \u003c\u003c \"Triggering callback...\" \u003c\u003c std::endl; callback(); } int main() { registerCallback([]() { std::cout \u003c\u003c \"Callback executed!\" \u003c\u003c std::endl; }); return 0; } ","date":"2024-12-17","objectID":"/posts/funtional/:5:1","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"事件驱动编程 在事件驱动编程中，可以用 std::function 存储事件处理器。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u003cfunctional\u003e #include \u003ciostream\u003e #include \u003cmap\u003e class EventManager { std::map\u003cstd::string, std::function\u003cvoid()\u003e\u003e events; public: void registerEvent(const std::string\u0026 name, std::function\u003cvoid()\u003e handler) { events[name] = handler; } void triggerEvent(const std::string\u0026 name) { if (events.count(name)) events[name](); } }; int main() { EventManager manager; manager.registerEvent(\"onStart\", []() { std::cout \u003c\u003c \"Start event triggered!\" \u003c\u003c std::endl; }); manager.registerEvent(\"onEnd\", []() { std::cout \u003c\u003c \"End event triggered!\" \u003c\u003c std::endl; }); manager.triggerEvent(\"onStart\"); manager.triggerEvent(\"onEnd\"); return 0; } ","date":"2024-12-17","objectID":"/posts/funtional/:5:2","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"策略模式 通过 std::function，可以动态设置逻辑。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u003cfunctional\u003e #include \u003ciostream\u003e void algorithmA() { std::cout \u003c\u003c \"Using Algorithm A\" \u003c\u003c std::endl; } void algorithmB() { std::cout \u003c\u003c \"Using Algorithm B\" \u003c\u003c std::endl; } class Context { std::function\u003cvoid()\u003e strategy; public: void setStrategy(std::function\u003cvoid()\u003e func) { strategy = func; } void execute() { strategy(); } }; int main() { Context context; context.setStrategy(algorithmA); context.execute(); context.setStrategy(algorithmB); context.execute(); return 0; } ","date":"2024-12-17","objectID":"/posts/funtional/:5:3","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"多线程中的任务分发 结合 std::function 和线程库，任务可以灵活地分发给不同的线程。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u003cfunctional\u003e #include \u003ciostream\u003e #include \u003cthread\u003e void task(int id) { std::cout \u003c\u003c \"Task \" \u003c\u003c id \u003c\u003c \" is running on thread \" \u003c\u003c std::this_thread::get_id() \u003c\u003c std::endl; } int main() { std::function\u003cvoid(int)\u003e func = task; std::thread t1(func, 1); std::thread t2(func, 2); t1.join(); t2.join(); return 0; } ","date":"2024-12-17","objectID":"/posts/funtional/:5:4","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function 与 std::move std::function是一个模板类，既然是类就必然有开销。C++11支持移动语义，可以使用 std::move 避免不必要的复制。 1 2 3 4 5 6 7 8 9 10 11 #include \u003cfunctional\u003e #include \u003ciostream\u003e int main() { auto lambda = [](int x) { std::cout \u003c\u003c \"Lambda executed with \" \u003c\u003c x \u003c\u003c std::endl; }; std::function\u003cvoid(int)\u003e func = std::move(lambda); // 移动 lambda func(10); return 0; } ","date":"2024-12-17","objectID":"/posts/funtional/:6:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function 的替代品 如果只需要封装普通函数，可以直接使用函数指针， 更加轻量 当类型已知或固定时，使用模板函数或 auto 可以避免 std::function 的动态分配和类型擦除开销。 C++17的std::invoke ","date":"2024-12-17","objectID":"/posts/funtional/:7:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"总结 ","date":"2024-12-17","objectID":"/posts/funtional/:8:0","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"std::function 的优缺点概述 优点： 灵活性高，支持普通函数、Lambda、仿函数、std::bind 对象等。 接口统一，易于组合和扩展。 适合需要动态行为的场景。 缺点： 动态分配带来的性能开销。 类型擦除机制导致间接调用，影响效率。 使用不当可能增加复杂度。 ","date":"2024-12-17","objectID":"/posts/funtional/:8:1","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"使用场景 需要存储多种类型的可调用对象。 动态注册和调用回调函数。 实现灵活的策略模式或事件机制。 ","date":"2024-12-17","objectID":"/posts/funtional/:8:2","tags":["C++","functional"],"title":"C++中的std::function","uri":"/posts/funtional/"},{"categories":["C++"],"content":"基本概念 在开始讲解左值和右值之前，咱们需要先理解两个基本概念：类型（Type）和值类别（Value Categories）。这两个概念经常被混淆，但它们其实是完全不同的东西。 ","date":"2024-12-17","objectID":"/posts/valuecategories/:1:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"1.1 Type vs Value Categories 想象你有一个快递包裹： Type（类型）就像是这个包裹的属性：是个箱子还是个信封，是大是小，是重是轻。 Value Categories（值类别）则像是这个包裹的状态：是在仓库里存放的，还是正在运输中的，或是即将被销毁的。 让我们用简单的代码来说明： 1 2 3 int x = 42; // x的类型(Type)是int int\u0026 ref = x; // ref的类型是int的引用 int\u0026\u0026 rref = 42; // rref的类型是int的右值引用 ","date":"2024-12-17","objectID":"/posts/valuecategories/:1:1","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"1.2 两者的关系 很多初学者会困惑：“左值引用\"和\"右值\"这两个概念看起来很像，但为什么有时候左值引用能指向右值？这是因为： “左值引用\"是一个类型（Type） “右值\"是一个值类别（Value Category） 就像快递包裹可以从仓库（左值）转变为运输状态（右值）一样，一个表达式的值类别也可以改变。 ","date":"2024-12-17","objectID":"/posts/valuecategories/:1:2","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"左值（lvalue） ","date":"2024-12-17","objectID":"/posts/valuecategories/:2:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"2.1 什么是左值？ 最简单的理解：左值就是可以取地址的表达式。想象你的家： 你的家有一个固定的地址 -\u003e 这就像左值 你可以随时回到这个地址 -\u003e 这就像可以多次访问左值 ","date":"2024-12-17","objectID":"/posts/valuecategories/:2:1","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"2.2 常见的左值例子： 1 2 3 4 5 6 int x = 10; // x是左值 string str = \"hello\"; // str是左值 int arr[10]; // arr是左值 // 你可以对左值取地址 int* ptr = \u0026x; // 正确：x是左值 ","date":"2024-12-17","objectID":"/posts/valuecategories/:2:2","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"将亡值（xvalue） ","date":"2024-12-17","objectID":"/posts/valuecategories/:3:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"3.1 什么是将亡值？ 将亡值就像是即将搬家的物品： 它现在还在原地（有确定位置） 但马上就要被移动到新地方了 移动后原来的位置就空了 ","date":"2024-12-17","objectID":"/posts/valuecategories/:3:1","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"3.2 最常见的将亡值例子： 1 2 3 string str = \"hello\"; string new_str = std::move(str); // str变成了将亡值 // 此时str还存在，但它的内容已经被移动走了 ","date":"2024-12-17","objectID":"/posts/valuecategories/:3:2","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"纯右值（prvalue） ","date":"2024-12-17","objectID":"/posts/valuecategories/:4:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"4.1 什么是纯右值？ 纯右值就像是临时的东西： 数字42 临时计算的结果 函数返回的临时对象 ","date":"2024-12-17","objectID":"/posts/valuecategories/:4:1","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"4.2 简单例子： 1 2 3 4 5 int x = 42; // 42是纯右值 int y = x + 1; // x + 1的结果是纯右值 string getName() { return \"John\"; // \"John\"是纯右值 } ","date":"2024-12-17","objectID":"/posts/valuecategories/:4:2","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"为什么需要这些概念？ 想象你在操作文件： 如果是把文件从一个目录拷贝到另一个目录（左值到左值）： 需要完整复制一份 费时费力 如果是把文件直接剪切到新目录（将亡值）： 直接移动过去就行 更快更省力 下面是一些实际使用案例（没有使用函数返回对象的例子是因为现代C++编译器都有RVO）： 容器元素转移： 1 2 3 4 5 6 7 8 class BigData { vector\u003cstring\u003e data; public: BigData(vector\u003cstring\u003e\u0026\u0026 vec) : data(std::move(vec)) {} // 移动构造 }; vector\u003cstring\u003e vec = {\"很长的字符串1\", \"很长的字符串2\", \"很长的字符串3\"}; BigData bd(std::move(vec)); // 如果不用move，会复制整个vector 在容器中重用对象 1 2 3 4 5 6 vector\u003cstring\u003e strings; string str = \"很长的字符串\"; strings.push_back(str); // 复制 strings.push_back(std::move(str)); // 移动，避免复制 // 此时str为空，可以重用 str = \"另一个很长的字符串\"; // 重用str unique_ptr的转移 1 2 3 4 5 6 7 8 9 10 11 class Resource { unique_ptr\u003cBigObject\u003e ptr; public: void setResource(unique_ptr\u003cBigObject\u003e\u0026\u0026 r) { ptr = std::move(r); // 必须使用move，unique_ptr不能复制 } }; Resource res; auto obj = make_unique\u003cBigObject\u003e(); res.setResource(std::move(obj)); // 必须move，否则编译错误 类成员的高效替换 1 2 3 4 5 6 7 8 class MyClass { vector\u003cstring\u003e data; public: void swap(MyClass\u0026 other) { data = std::move(other.data); // 高效移动而不是复制 other.data = std::move(data); // 恢复other的数据 } }; 在STL算法中移动元素 1 2 3 4 5 6 7 vector\u003cstring\u003e source = {\"长字符串1\", \"长字符串2\", \"长字符串3\"}; vector\u003cstring\u003e dest; // 移动而不是复制元素 std::copy(std::make_move_iterator(source.begin()), std::make_move_iterator(source.end()), std::back_inserter(dest)); // source中的字符串现在都是空的 ","date":"2024-12-17","objectID":"/posts/valuecategories/:5:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"实际应用建议 ","date":"2024-12-17","objectID":"/posts/valuecategories/:6:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"对于初学者： 当你需要转移一个大对象的所有权时，使用std::move： 1 2 3 4 string str = \"hello\"; vector\u003cstring\u003e vec; vec.push_back(std::move(str)); // str的内容被移动到vector中 // 注意：此时str变成了空字符串 注意移动后的对象状态： 1 2 3 string str = \"hello\"; string new_str = std::move(str); // 此时str是空的，不要继续使用它 使用不可复制但是可以移动的类型如unique_ptr时。 不要对const对象使用’std::move’。 ","date":"2024-12-17","objectID":"/posts/valuecategories/:6:1","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"总结 类型（Type）和值类别（Value Categories）是不同的概念 左值是可以取地址的表达式 将亡值是可以被移动的对象 纯右值是临时的值 这些概念初看可能很复杂，但随着你的C++编程经验增加，它们会变得越来越清晰。不要期望一次就完全理解，这是一个渐进的过程。 ","date":"2024-12-17","objectID":"/posts/valuecategories/:7:0","tags":["C++","Value Categories"],"title":"深入浅出C++中的左值与右值","uri":"/posts/valuecategories/"},{"categories":["C++"],"content":"循环引用会导致什么 正常的对象在生命周期结束后应该就释放持有的资源了, 但是如果两个shared_ptr对象互相指向对方, 在生命周期结束后两个变量确实会被销毁, 但是他们两个持有的资源依然会在内存中, 此时就引起了内存泄漏. ","date":"2024-12-15","objectID":"/posts/shared_ptr/:1:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"典型的循环引用场景 首先来看一个典型的循环引用场景: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Node { public: std::shared_ptr\u003cNode\u003e next; // 指向下一个节点 std::shared_ptr\u003cNode\u003e prev; // 指向前一个节点 int data; Node(int d) : data(d) { std::cout \u003c\u003c \"Node \" \u003c\u003c data \u003c\u003c \" created\\n\"; } ~Node() { std::cout \u003c\u003c \"Node \" \u003c\u003c data \u003c\u003c \" destroyed\\n\"; } }; void createNodes() { auto node1 = std::make_shared\u003cNode\u003e(1); auto node2 = std::make_shared\u003cNode\u003e(2); // 创建循环引用 node1-\u003enext = node2; node2-\u003eprev = node1; // 函数结束时，即使局部变量node1和node2被销毁 // 由于循环引用，这些Node对象也不会被删除 } 如上所示, 当调用完createNodes后, 按理来说两个临时对象都应该被销毁, 但实际上两个对象被销毁后, Node对象依然存在, 因为两个Node的引用计数不为0. 1 2 3 4 5 6 7 8 int main() { createNodes(); // 你会看到Node被创建的输出 // 但不会看到Node被销毁的输出 // 这表明发生了内存泄漏 std::cout \u003c\u003c \"Program ending\\n\"; } ","date":"2024-12-15","objectID":"/posts/shared_ptr/:2:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"观察者模式中的循环引用 来看代码, 在观察者模式中, 如果观察者和被观察者互相持有对方的引用(观察者需要知道观察对象的状态, 观察对象想知道被几个对象观察), 那么就会发生循环引用. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 观察者模式中常见的循环引用 class Subject; class Observer { public: std::shared_ptr\u003cSubject\u003e subject; // 持有Subject的引用 virtual ~Observer() { std::cout \u003c\u003c \"Observer destroyed\\n\"; } }; class Subject { public: std::vector\u003cstd::shared_ptr\u003cObserver\u003e\u003e observers; // 持有Observer的引用 virtual ~Subject() { std::cout \u003c\u003c \"Subject destroyed\\n\"; } }; void test() { auto subject = std::make_shared\u003cSubject\u003e(); auto observer = std::make_shared\u003cObserver\u003e(); // 建立循环引用 subject-\u003eobservers.push_back(observer); observer-\u003esubject = subject; // 函数结束时，两个对象都不会被销毁 } ","date":"2024-12-15","objectID":"/posts/shared_ptr/:3:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"如何检测循环引用 直接通过调试或者打日志的方式来观察引用计数： 1 LOGI(ptr.use_count()); 如果发现对象的引用计数一直不为0，就可能存在循环引用。 使用内存泄漏工具 老生常谈了，使用Valgrind，ASAN等工具来进行排查 Code Review 检查类之间依赖关系 检查互相持有shared_ptr的类 ","date":"2024-12-15","objectID":"/posts/shared_ptr/:4:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"循环引用的解决方案 ","date":"2024-12-15","objectID":"/posts/shared_ptr/:5:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"Node循环引用的解决方案 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Node { public: std::shared_ptr\u003cNode\u003e next; // 强引用 std::weak_ptr\u003cNode\u003e prev; // 弱引用 int data; Node(int d) : data(d) { std::cout \u003c\u003c \"Node \" \u003c\u003c data \u003c\u003c \" created\\n\"; } ~Node() { std::cout \u003c\u003c \"Node \" \u003c\u003c data \u003c\u003c \" destroyed\\n\"; } void process() { // 使用weak_ptr时需要先lock if (auto p = prev.lock()) { std::cout \u003c\u003c \"Previous node data: \" \u003c\u003c p-\u003edata \u003c\u003c \"\\n\"; } } }; ","date":"2024-12-15","objectID":"/posts/shared_ptr/:6:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"观察者模式循环引用的正确实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Subject; class Observer { public: std::weak_ptr\u003cSubject\u003e subject; // 使用weak_ptr virtual ~Observer() { std::cout \u003c\u003c \"Observer destroyed\\n\"; } }; class Subject { public: std::vector\u003cstd::weak_ptr\u003cObserver\u003e\u003e observers; // 使用weak_ptr void notify() { // 清理失效的观察者并通知有效的观察者 for (auto it = observers.begin(); it != observers.end();) { if (auto observer = it-\u003elock()) { // 通知观察者 ++it; } else { it = observers.erase(it); // 移除失效的观察者 } } } virtual ~Subject() { std::cout \u003c\u003c \"Subject destroyed\\n\"; } }; ","date":"2024-12-15","objectID":"/posts/shared_ptr/:7:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["C++"],"content":"最佳实践 在设计类关系时, 就要明确所有权关系. 比如父子关系, 父对象使用share_ptr, 子对象使用weak_ptr指向父对象. 比如观察者模式中Subject持有Observer的weak_ptr, 同时定期检查weak_ptr是否过期, 清理无效的引用. 同时注意在使用weak_ptr会带来一定的性能开销, 因为要检查和上锁, 因此在多线程环境需要特别注意weak_ptr的使用, 最好的解决方案还是在设计时就避免循环引用. ","date":"2024-12-15","objectID":"/posts/shared_ptr/:8:0","tags":["C++","Memory","Smart Pointer"],"title":"C++ shared_ptr 循环引用","uri":"/posts/shared_ptr/"},{"categories":["Algo"],"content":"算法组件 一般算法中存在两个进程, 一个SLAM, 一个Navigator, SLAM负责建图与定义, Navigator负责移动与规划. ","date":"2024-12-15","objectID":"/posts/overview/:1:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"SLAM (Simultaneous Localization and Mapping) SLAM是同时定位与建图的过程。在扫地机场景中，SLAM使得机器人可以在未知或半未知的室内环境中，自主构建环境地图，并基于该地图确定自身在环境中的位置和姿态。通过SLAM，扫地机能够在清洁过程中不断修正自己的路线和定位，以实现对复杂、多变环境的高效清扫。 ","date":"2024-12-15","objectID":"/posts/overview/:2:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"Location（定位） 定位算法主要采用SVM (Support Vector Machine) Match的方式。这一过程通常包括以下步骤： 特征提取：从传感器数据（如激光雷达点云）中提取环境特征点或关键特征（如墙壁、家具边缘）。 特征匹配：使用SVM或其他机器学习方法，将当前观测到的特征与已有地图中的特征进行匹配，从而推断当前扫地机所在的位姿（位置与朝向）。 位置估计更新：将匹配结果融合至估计器（如卡尔曼滤波器或粒子滤波器），得到更加稳定且实时的定位结果。随着时间推移，这种估计会不断修正和更新，为后续路径规划和导航提供精确的参考。 ","date":"2024-12-15","objectID":"/posts/overview/:3:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"Mapping（建图） 建图过程主要采用GMapping算法，这是基于粒子滤波（PF）和RBPF（Rao-Blackwellized Particle Filter）框架的一种经典2D激光SLAM方案。通过对激光雷达扫描数据和里程计信息进行融合和滤波，GMapping能够得到较为精确和稠密的网格地图。但在一些场景下（例如较长、较狭长的走廊或者较大的室内场地），GMapping可能存在局部优化困难或误差积累的问题。 为应对这些问题，可以引入PSO（粒子群优化）或IPSO（改进粒子群优化）进行全局优化与矫正： 数据来源：主要来自激光雷达（LIDAR）的扫描数据，这些数据为建图提供环境的几何信息。 数据处理：对雷达数据进行汇总、降噪、过滤，提取稳定特征。必要时对场景进行分块处理、或者增加闭环检测（Loop Closure）手段以减少累积误差。 优化过程：在出现长轴走廊或大空间区域时，通过PSO/IPSO对粒子滤波产生的估计进行全局搜索与优化，减少地图偏移和扭曲，从而提高地图的整体一致性。 另外谷歌开源了Cartographer框架, 通过Cartographer，设备可在未知环境中持续获取自身位姿（位置与方向），同时构建出高精度的环境地图。 ","date":"2024-12-15","objectID":"/posts/overview/:4:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"运行逻辑 典型的运行逻辑可以分为数据采集、数据处理、状态切换与结果输出几个环节： 数据轮询： 主线程（或独立的传感器线程）以固定频率轮询雷达数据，并将新获得的扫描数据放入处理队列。 状态机驱动： 系统内部存在一个状态机（State Machine），根据扫地机当前的定位精度、地图构建进度、清扫状态及命令输入等因素进行状态切换。 常见状态包括：初始化（等待首帧数据与初始位姿）、构图（不断更新地图）、定位（在已有地图中精确定位）、导航（基于定位结果进行路径规划）和完成态（清扫完成、待机等）。 数据更新与算法执行： 对新获取的激光雷达数据进行预处理（滤波、特征提取）。 将预处理结果输入GMapping进行地图更新，并将结果传递给SVM匹配模块以辅助定位。 如遇特定场景或累积误差较大时，触发PSO/IPSO全局优化，以校正地图偏差。 结果分发与协议输出： 当地图和定位结果更新完成后，通过规定的通信协议（如内部总线消息队列、TCP/IP、串口协议等）将位姿、地图更新信息发送给上层控制模块或UI模块，以便其他功能模块（如路径规划、避障决策、执行控制）作出相应反应。 持续循环迭代： 整个过程随着扫地机移动、环境变化与实时数据输入不断重复。通过持续的感知—处理—反馈环路，扫地机在实时构建地图、精确定位的同时，对自身行进方向和策略进行动态调整，从而实现更智能、高效的清洁作业。 总结 通过上述补充，SLAM系统不仅仅是简单的\"同时定位与建图\"的技术堆叠，而是一个包含数据采集、算法处理、状态管理、全局优化及结果传输的复杂系统架构。在该框架下，SVM用于提升定位的匹配精度，GMapping用于高效构建地图，PSO/IPSO作为优化手段则帮助在复杂环境下校正地图，使扫地机在真实家庭或商业场景中拥有更稳定可靠的自主运行能力。 ","date":"2024-12-15","objectID":"/posts/overview/:5:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"Navigator Navigator是扫地机实现自主导航与路径规划的核心模块，负责根据SLAM建图与定位数据以及上层任务指令，计算出有效的运动路径，并通过执行层实现机器人在室内环境中的自主移动。 ","date":"2024-12-15","objectID":"/posts/overview/:6:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"组件组成： SLAM组件 功能：接收SLAM模块提供的环境地图（如网格地图、占据栅格地图）和机器人当前精确位置与姿态信息。 数据输入：位置（x, y, θ），环境地图更新（动态更新增加已探索区域，修正局部地图特征）。 作用：为导航决策提供全局环境认知与当前状态参考。 Task组件（任务控制） 功能：接受上层调度组件或其他进程的命令事件（如清扫指定房间、返回充电桩、避开特定区域），并将这些高层任务目标下达给Navigator。 作用：决定导航最终的目标点（Goal）、执行策略和优先级。 对Navigator而言，Task组件相当于\"外部命令与目标的发起者\"，由其给出下一步行动计划。 Map、Path子组件（地图与路径规划） Map管理： 维护SLAM生成的全局/局部地图数据结构。当SLAM有新的地图数据更新时，该组件会对地图进行相应处理，如标记已清洁区域、标记动态障碍物位置、根据传感器数据更新占用信息。 Path规划（Path Planner）： 主要算法为A*（A-star）。A在已知的网格地图上从当前坐标出发寻找到达目标点的最优（或较优）路径。 在实际应用中，A会结合代价地图（Costmap），考虑行走代价（障碍物、墙壁、禁行区）和安全距离，给出可实现的可行路径。如果环境发生变化（例如前方出现新的障碍），Path Planner可能会动态重新规划路径。 Motion组件（运动控制） 功能：将Path Planner得到的路径分解为一系列底层运动控制指令（如速度、转向角）并发送给底层驱动模块（电机控制器）。 作用：负责实际将路径转化为机器人可执行的运动命令，从而让机器人沿规划路径移动。 通常Motion组件还包含姿态跟踪与误差反馈（闭环控制），根据实时位置偏差不断进行微调，保证机器人沿预期路径前进。 Perception组件（环境感知） 功能：对传感器数据（包括激光雷达、红外/超声传感器、碰撞传感器）进行感知与识别，如检测临时障碍物（桌腿、椅子、杂物）。 作用：在导航过程中不断感知环境变化，将新识别的障碍信息传递给Map管理子组件或直接反馈给Path Planner，以便进行路径调整。 ","date":"2024-12-15","objectID":"/posts/overview/:7:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Algo"],"content":"运行逻辑： 任务触发： Task组件收到来自上层（清洁任务管理模块或用户命令）的事件，例如： 清洁指定区域 返回基站充电 移动到特定坐标 状态与地图更新： 导航器首先从SLAM获取当前机器人位置和更新后的地图信息，并同步给Map管理子组件，确保环境认知和位姿数据最新有效。 路径规划执行： 一旦任务目标确定，Path Planner使用A*算法在当前地图中搜索从机器人当前位置到目标点的可行路径。 若环境狭窄或复杂，Perception组件的数据可能要求规划器避让临时障碍。 若A*无法找到路径，Navigator会尝试修改目标点或等待环境变化后重新计算。 路径下达与运动控制： 得到路径后，Navigator将路径传给Motion组件。Motion组件将路径分解为连续的速度与转向指令，驱动底层马达控制器，使机器人沿路径移动。 动态反馈与调整： 在机器人移动过程中，Perception组件持续感知周围环境。如果出现新障碍物、SLAM对地图进行了更新，Navigator会根据变化决定是否需要实时重新规划路径（重复步骤3）。 任务完成与回馈： 当机器人达到目标点或完成任务范围清洁后，Navigator会通过Task组件向上层反馈任务完成状态。上层组件可继续下发新任务或让机器人进入待机模式。 总结： 完整的Navigator体系通过SLAM的定位与建图信息获得环境与自身的动态认知，由Task组件下达高层任务，Path Planner（A*）负责为这些任务分配可行的路线，Motion组件负责将路线执行到底层行动，Perception组件则保证在变化的环境中对路径与决策进行适时调整。这种环环相扣的架构确保了扫地机在实际家居环境中高效、稳定、智能地自主导航与清扫。 ","date":"2024-12-15","objectID":"/posts/overview/:8:0","tags":["Algo","Overview"],"title":"移动机器人算法Overview","uri":"/posts/overview/"},{"categories":["Linux"],"content":"线程与进程的创建过程差异在哪里🧐","date":"2024-08-18","objectID":"/posts/a7f3bdf/","tags":["Linux","Process"],"title":"进程与线程的创建","uri":"/posts/a7f3bdf/"},{"categories":["Linux"],"content":"线程和进程的创建过程 看到这个标题的第一反应你的想法是什么呢, 是不是觉得在Linux中线程和进程的创建流程可以会有很大的不一样, 实际上, 从内核的视角来看, 线程和进程的创建基本是一样的, 都是调用clone系统调用, 只不过传递的参数不一样而已, 下面我们就来分析一下clone系统调用的过程. ","date":"2024-08-18","objectID":"/posts/a7f3bdf/:1:0","tags":["Linux","Process"],"title":"进程与线程的创建","uri":"/posts/a7f3bdf/"},{"categories":["Linux"],"content":"clone系统调用 clone系统调用是Linux中创建线程和进程的底层实现, 它的函数原型如下: 1 long clone(int (*fn)(void *), void *child_stack, int flags, void *arg, pid_t *ptid, struct user_desc *tls, pid_t *ctid); clone系统调用的参数如下: fn: 子进程/线程的入口函数 child_stack: 子进程/线程的栈空间 flags: 创建进程/线程的标志 arg: 传递给子进程/线程的参数 ptid: 父进程/线程的线程ID tls: 线程局部存储 ctid: 子进程/线程的线程ID clone系统调用的返回值如下: 成功: 返回子进程/线程的线程ID graph TD A[fork] --\u003e B[sys_fork] B --\u003e C[do_fork] C --\u003e D[clone CLONE_PARENT] D --\u003e E[copy_process] E --\u003e F[copy_mm] E --\u003e G[copy_fs] E --\u003e H[copy_files] E --\u003e I[copy_sighand] E --\u003e J[copy_thread] E --\u003e K[wake_up_new_task] graph TD A[fork] --\u003e B[sys_fork] B --\u003e C[do_fork] C --\u003e D[clone CLONE_PARENT] D --\u003e E[copy_process] E --\u003e F[copy_mm] E --\u003e G[copy_fs] E --\u003e H[copy_files] E --\u003e I[copy_sighand] E --\u003e J[copy_thread] E --\u003e K[wake_up_new_task]","date":"2024-08-18","objectID":"/posts/a7f3bdf/:1:1","tags":["Linux","Process"],"title":"进程与线程的创建","uri":"/posts/a7f3bdf/"},{"categories":["编译"],"content":"clangd的工作原理 clangd 是一个基于 Clang 的语言服务器，实现了语言服务器协议（LSP），用于提供 C/C++ 项目的智能代码编辑功能，如代码补全、跳转到定义、查找引用等。 clangd 的工作流程如下: ","date":"2024-08-17","objectID":"/posts/0817/:1:0","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["编译"],"content":"启动和初始化 在启动VS code时(VS code内部支持LSP), 如果clangd已经安装, 那么就会自动启动, VS code和clangd通过LSP协议进行通信, clangd会进行初始化, 包括读取配置文件、加载索引和缓存等。 ","date":"2024-08-17","objectID":"/posts/0817/:1:1","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["编译"],"content":"读取配置文件 clangd 会读取配置文件，读取顺序为.clangd 文件, compile_commands.json 文件, clang-tidy 配置, clang-format 配置. • clangd 首先加载 .clangd 文件，这个文件配置了 clangd 的基本行为和选项。 • compile_commands.json 紧随其后被加载，用于提供项目的具体编译信息。它在 clangd 的配置文件之后加载，但对 clangd 的核心功能影响很大，因为它定义了如何解析项目代码。 • clang-tidy 和 clang-format 的配置在此之后加载，并影响代码的静态分析和格式化。 ","date":"2024-08-17","objectID":"/posts/0817/:1:2","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["编译"],"content":"索引和缓存 clangd 会索引项目中的源文件，并将索引信息存储在缓存中。索引过程包括解析源文件、提取符号信息、构建符号之间的依赖关系等。索引信息可以加速后续的代码分析，如跳转到定义、查找引用等操作。 在索引时, vscode中可以看到左下角的index, 还会显示进度. 索引完成后, 这个提示会消失. ","date":"2024-08-17","objectID":"/posts/0817/:1:3","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["编译"],"content":"处理编辑器请求 当编辑器发出请求时，如代码补全、跳转到定义、查找引用等，clangd 会根据请求类型和索引信息进行处理。处理结果会以 JSON 格式返回给编辑器，编辑器会根据结果进行相应的操作，如显示补全列表、跳转到定义等。 ","date":"2024-08-17","objectID":"/posts/0817/:1:4","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["编译"],"content":"处理动态变化 主要涉及的动作有两个 • 文件变化检测: clangd 会监视项目中的文件变化。当文件被修改、添加或删除时，它会自动更新索引和缓存，以确保提供的智能编辑功能始终是最新的。 • 重新加载编译数据库: 如果 compile_commands.json 文件发生变化，clangd 会自动重新加载它，并根据新的编译选项更新编译上下文和索引。 ","date":"2024-08-17","objectID":"/posts/0817/:1:5","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["编译"],"content":"关闭 在关闭vscode的时候,clangd 会自动停止运行，并清理内存中加载的缓存和索引数据。不过，clangd 通常会将索引结果持久化到磁盘，以便在下次启动时加快加载速度。 ","date":"2024-08-17","objectID":"/posts/0817/:1:6","tags":["编译"],"title":"Clangd工作原理","uri":"/posts/0817/"},{"categories":["Linux"],"content":"进程和线程的区别远远没你想象中的大!🤯","date":"2024-08-17","objectID":"/posts/f1a5e95/","tags":["Linux","Process"],"title":"进程与线程的区别","uri":"/posts/f1a5e95/"},{"categories":["Linux"],"content":"进程和线程 在网上大部分的介绍中, 总习惯于说明进程和线程的区别, 但是从内核的视角来看, 线程和进程的相同点远远大于不同点. 在内核的实现中, 将线程和进程统称为任务, 都是用一种结构体(task_struct)来表示, 在调度上没有任何区别, 上下文切换的开销也没太大区别. 线程的上下文切换的开销会比进程的上下文切换稍微小点, 能少点的原因是如果两个线程属于同一个进程, 那么切换的时候, 不需要切换进程的地址空间, 只需要切换线程的栈和寄存器. ","date":"2024-08-17","objectID":"/posts/f1a5e95/:1:0","tags":["Linux","Process"],"title":"进程与线程的区别","uri":"/posts/f1a5e95/"},{"categories":["Linux"],"content":"进程和线程的相同点 ","date":"2024-08-17","objectID":"/posts/f1a5e95/:1:1","tags":["Linux","Process"],"title":"进程与线程的区别","uri":"/posts/f1a5e95/"},{"categories":["Linux"],"content":"进程和线程的区别 ","date":"2024-08-17","objectID":"/posts/f1a5e95/:1:2","tags":["Linux","Process"],"title":"进程与线程的区别","uri":"/posts/f1a5e95/"},{"categories":["设计模式"],"content":"观察者模式 观察者模式（Observer Pattern）是一种行为设计模式，它定义了对象之间的一对多依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知并自动更新。 观察者模式的主要组成部分包括： 主题（Subject）：主题是观察者模式的核心，它维护了一个观察者列表，并提供了添加、删除和通知观察者的方法。 观察者（Observer）：观察者是依赖于主题的对象，它实现了观察者接口，并在接收到主题的通知时更新自己的状态。 具体主题（Concrete Subject）：具体主题是主题的具体实现，它包含了主题的状态，并在状态发生改变时通知观察者。 具体观察者（Concrete Observer）：具体观察者是观察者的具体实现，它包含了观察者的状态，并在接收到主题的通知时更新自己的状态。 观察者模式的主要优点包括： 松耦合：观察者模式将主题和观察者解耦，使得它们可以独立地变化和扩展。 可扩展性：观察者模式可以很容易地添加新的观察者或主题，而不需要修改现有的代码。 灵活性：观察者模式可以灵活地控制观察者的通知顺序和频率。 观察者模式的主要缺点包括： 性能问题：当观察者数量较多时，通知观察者的开销可能会变得很大。 复杂性：观察者模式可能会增加系统的复杂性，特别是在处理复杂的依赖关系时。 观察者模式的应用场景包括： 事件驱动系统：观察者模式可以用于实现事件驱动系统，例如GUI应用程序中的事件处理。 消息队列：观察者模式可以用于实现消息队列，例如发布/订阅模型。 数据绑定：观察者模式可以用于实现数据绑定，例如MVC框架中的视图和模型之间的绑定。 观察者模式是一种常用的设计模式，它可以帮助我们实现对象之间的松耦合和可扩展性，提高系统的灵活性和可维护性。· ","date":"2024-08-17","objectID":"/posts/observer/:1:0","tags":["观察者模式"],"title":"观察者模式","uri":"/posts/observer/"},{"categories":["Leecode","Git"],"content":"Leetcode 2216 直接模拟 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Solution { public: int minDeletion(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); int cnt = 0; for (int i = 0; i \u003c n - 1; ++i) { if ((i - cnt) % 2 == 0 \u0026\u0026 nums[i] == nums[i + 1]) { cnt++; } } if ((n - cnt) % 2 == 1) return cnt + 1; return cnt; } }; ","date":"2024-08-06","objectID":"/posts/leetcode2216/:1:0","tags":["Leetcode"],"title":"Leetcode2216","uri":"/posts/leetcode2216/"},{"categories":["Leecode","Git"],"content":"虚拟节点的用处 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:0","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"},{"categories":["Leecode","Git"],"content":"1. 链表操作 删除链表 在删除链表节点时，特别是删除头节点，通常需要对头节点进行特殊处理。引入一个虚拟头节点，可以统一删除节点的操作逻辑，无需特判头节点。例如： 1 2 3 4 5 6 7 8 9 10 11 ListNode* dummy = new ListNode(0); dummy-\u003enext = head; ListNode* current = dummy; while (current-\u003enext != nullptr) { if (current-\u003enext-\u003eval == value) { current-\u003enext = current-\u003enext-\u003enext; break; } current = current-\u003enext; } return dummy-\u003enext; 合并链表, 在合并两个有序链表时，使用虚拟头节点可以避免初始化第一个节点的特殊处理。 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:1","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"},{"categories":["Leecode","Git"],"content":"2. 树操作 层序遍历, 在二叉树的层序遍历中，使用虚拟节点（如在每层之间加入一个特殊的 null 节点）可以方便区分不同的层级，简化层级分隔的处理。 构建环形链表, 在处理一些树或者图结构时，引入一个虚拟根节点可以将非平衡的树结构转换为更容易处理的形式，尤其是在做序列化、反序列化或者复杂遍历时。 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:2","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"},{"categories":["Leecode","Git"],"content":"3. DP中的状态转移 状态初始化：在一些动态规划问题中（如背包问题、最短路径问题），引入虚拟节点或状态可以统一处理初始状态与一般状态的转移，避免对初始条件的特殊处理。 二维动态规划：如之前的例子，虚拟节点可以用来简化动态规划中的边界条件处理，使得状态转移方程更为统一和简洁。 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:3","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"},{"categories":["Leecode","Git"],"content":"4.图算法： 最短路径：在计算多个节点的最短路径时，可以引入一个虚拟源节点，连接所有原始节点，来简化处理每个节点的初始路径计算。 拓扑排序：在拓扑排序中，引入虚拟节点可以方便处理那些没有入度的节点，统一处理初始条件。 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:4","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"},{"categories":["Leecode","Git"],"content":"5.字符串匹配： KMP算法：在KMP字符串匹配算法中，引入虚拟节点可以用于简化前缀表（失败函数）的初始化处理，使得主串与模式串的匹配过程更加顺畅。 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:5","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"},{"categories":["Leecode","Git"],"content":"6.其他场景： 多源汇流问题：在流网络中，可以通过添加虚拟源点或汇点来将多源或多汇问题转换为单源单汇问题，从而简化算法设计。 ","date":"2024-08-06","objectID":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/:1:6","tags":["Leetcode"],"title":"虚拟节点的用处","uri":"/posts/%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9/"}]